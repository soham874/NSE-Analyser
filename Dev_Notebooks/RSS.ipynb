{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7a5164-6c2b-48c8-866e-f821b1cb022b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import feedparser\n",
    "from newspaper import Article\n",
    "import html\n",
    "\n",
    "\"\"\"\n",
    "Every minute;\n",
    "1. Fetch feed for all RSS URLs. Filter out feed data for last 30 min. - done\n",
    "2. Maintain a cache with TTL of 60 min. If the current feed title does not exist in the cache, push it and add it to processinglist\n",
    "4. For each of this title, analyse the news\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def get_summary(url):\n",
    "    article = Article(url)\n",
    "    article.download()\n",
    "    article.parse()\n",
    "    #print(\"Authors:\", article.authors)\n",
    "    return article.text\n",
    "\n",
    "def get_articles(url):\n",
    "    feed = feedparser.parse(url)\n",
    "    for entry in feed.entries:\n",
    "        title = entry.title\n",
    "        #description = entry.summary\n",
    "        published_date = entry.published\n",
    "        text = get_summary(entry.links[0]['href'])\n",
    "        print(f\"{published_date} - {html.unescape(title)}\")\n",
    "        #print(f\"Published: {published_date}\")\n",
    "        #print(f\"Text: {text}\")\n",
    "        print(\"----------------------------------------------------------------------------------------------------\")\n",
    "\n",
    "get_articles('https://www.cnbctv18.com/commonfeeds/v1/cne/rss/economy.xml')\n",
    "# get_articles('https://rss.app/feeds/tgll9PXJFaUoCjGV.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81eeca82-94e8-4567-ac50-5f3a6cea4189",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "feed = feedparser.parse('https://www.cnbctv18.com/commonfeeds/v1/cne/rss/economy.xml')\n",
    "feed = feed.entries\n",
    "\n",
    "current_timestamp = time.mktime(time.gmtime())\n",
    "window = 60\n",
    "\n",
    "for i in range(len(feed)-1 , -1, -1):\n",
    "    print(feed[i])\n",
    "    published_ts = time.mktime(feed[i].get('published_parsed'))\n",
    "    if current_timestamp - published_ts > window:\n",
    "        del feed[i]\n",
    "\n",
    "print(feed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071196e6-929b-4957-89ea-39d531d0fb2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "url = \"https://in.investing.com/news/stock-market-news/market-outlook-rbi-mpc-q2-results-iip-data-key-factors-to-watch-next-week-4459037\"\n",
    "\n",
    "payload = \"\"\n",
    "headers = {\n",
    "    \"User-Agent\": \"insomnium/0.2.3-a\"\n",
    "}\n",
    "\n",
    "response = requests.request(\"GET\", url, headers=headers)\n",
    "\n",
    "#print(response.text)\n",
    "\n",
    "article = Article('')\n",
    "article.set_html(response.text)\n",
    "article.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89a8ae1-6d7b-4c1e-86ae-1edfbc2e780d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the article\n",
    "article.parse()\n",
    "\n",
    "# Now you can access the parsed content\n",
    "print(\"Title:\", article.title)\n",
    "print(\"Text:\", article.text)\n",
    "print(\"Authors:\", article.authors)\n",
    "print(\"Published Date:\", article.publish_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1046c092-9661-49e3-b3a9-37d9a761e006",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.request(\n",
    "    method=\"GET\",\n",
    "    headers={\n",
    "        \"User-Agent\": \"insomnium/0.2.3-a\"\n",
    "    },\n",
    "    url=\"https://www.business-standard.com/rss/markets-106.rss\"\n",
    ")\n",
    "\n",
    "if not 200 <= response.status_code < 400:\n",
    "    raise Exception (f\"Failed to fetch feed from RSS {url}\")\n",
    "\n",
    "feedData = feedparser.parse(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2005ec68-c5e5-4550-b7f8-1baac0bf51a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "article.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b297683-21c8-427d-a345-f8acf77204f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import requests\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "url = \"https://in.investing.com/news/stock-market-news/market-outlook-rbi-mpc-q2-results-iip-data-key-factors-to-watch-next-week-4459037\"\n",
    "\n",
    "payload = \"\"\n",
    "headers = {\n",
    "    \"User-Agent\": \"insomnium/0.2.3-a\"\n",
    "}\n",
    "\n",
    "response = requests.request(\"GET\", url, headers=headers)\n",
    "\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "# Example: Extract the text from all <p> tags (adjust according to the HTML structure)\n",
    "\n",
    "# Find the specific <script> tag containing the desired data\n",
    "# For example, assuming the data is embedded in a script tag containing \"window.articleData\" or similar\n",
    "script_tags = soup.find_all('script', type='application/ld+json')\n",
    "\n",
    "# Initialize a variable to hold the article body\n",
    "article_body = None\n",
    "\n",
    "# Loop through all script tags and look for the NewsArticle\n",
    "for script_tag in script_tags:\n",
    "    try:\n",
    "        # Parse the JSON content\n",
    "        data = json.loads(script_tag.string)\n",
    "        \n",
    "        # Check if it's of type NewsArticle and extract the articleBody\n",
    "        if data.get('@type') == 'NewsArticle':\n",
    "            article_body = data.get('articleBody')\n",
    "            break  # Exit loop after finding the first NewsArticle\n",
    "    except json.JSONDecodeError:\n",
    "        continue  # Skip any script that does not contain valid JSON\n",
    "\n",
    "# Print the extracted article body\n",
    "if article_body:\n",
    "    print(\"Article Body:\", article_body)\n",
    "else:\n",
    "    print(\"Article Body not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf6cf11-d1c8-49ab-a9a2-9d36bfa3ee42",
   "metadata": {},
   "outputs": [],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fefab3bf-c49c-4468-ad5b-5566392bd69d",
   "metadata": {},
   "outputs": [],
   "source": [
    "requests.request(\"GET\",\"https://b2b.tijorifinance.com/b2b/v1/in/kite-widget/web/equity/TRIDENT/?exchange=NSE&broker=kite&theme=dark\"\n",
    "                ,headers={\n",
    "                    \"User-Agent\" : \"insomnium/0.2.3-a\"\n",
    "                }\n",
    "                ).text"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
